{
 "metadata": {
  "name": "everything.me 2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classifying Movies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We want to build a classifier. We will first try to find some features that give a good contrast between the genres.\n",
      "\n",
      "To do that, we will first tokenize the words in the plot name"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The Gameplan"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will try to use a naive bayessian classifier. But the main problem would be to choose the features.\n",
      "\n",
      "Possible features would be the words in the plot, the words in the title, combinations of words, length of description, year the moview came out, etc.\n",
      "\n",
      "We will try to use just the 1-grams (single words) first and see if they are good enough, since they are certainly the ones to hold the most information.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Loading the training set and tokenizing it"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import pprint\n",
      "from time import time\n",
      "import nltk\n",
      "from collections import defaultdict\n",
      "import pickle\n",
      "import re\n",
      "import numpy as np\n",
      "import os\n",
      "pp = pprint.PrettyPrinter(indent=6)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_training_set(trainingFileName):\n",
      "    movies = []\n",
      "    cnt = 0\n",
      "    L = 3000\n",
      "    for line in open(trainingFileName):\n",
      "        if cnt%L == L-1:\n",
      "            print 'Finished processing ' + str(len(movies)) + ' movies'\n",
      "        movies.append(json.loads(line))\n",
      "    return movies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "movies = load_training_set('movies_train.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "We need to tokenize and stem the 1-grams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a need to normalize some words (for example 'athlete','athletes' and 'athletics') in order to better group similar words to gain stronger and more stable statistics.\n",
      "\n",
      "Therefore we will use a stemmer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def delete_file(filename):\n",
      "    name = os.path.join('.', filename)\n",
      "    try:        \n",
      "        os.remove(name)\n",
      "        print 'old file deleted, ' + name\n",
      "    except:\n",
      "        print 'no previous file found ' + name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pos_tag_plots(movies, is_save=False):\n",
      "    stemmer = nltk.stem.snowball.EnglishStemmer()\n",
      "    n_movies = []\n",
      "    tic = time()\n",
      "    tokens = {}\n",
      "    pos_tags = {}\n",
      "    L=10000\n",
      "    if is_save:\n",
      "        delete_file('movies_tokenized.json')\n",
      "    for movie in movies:\n",
      "        n_movies.append(movie)\n",
      "        name = movie['name']\n",
      "        # we print out every once in a while, for a keepalive\n",
      "        if len(n_movies)%L == L-1:\n",
      "            print 'Finished processing ' + str(len(n_movies)) + ' movies'\n",
      "        preprocess = [stemmer.stem(token) for token in nltk.word_tokenize(movie['plot'].lower())]\n",
      "        \n",
      "#        if re.match('^[\\w-|!|?]+$', 'hell0') == None:\n",
      "#            continue\n",
      "        n_movies[-1]['tokens'] = [x for x in preprocess if (not re.match('^[\\w-]+$', x) == None)]\n",
      "        if is_save:\n",
      "            with open('movies_tokenized.json','a') as fid:\n",
      "                json.dump(n_movies[-1],fid)\n",
      "                fid.write('\\n')\n",
      "    toc = time()\n",
      "    print 'Done with ' + str(len(n_movies)) + '! ' + str((toc-tic)/float(len(n_movies))) + ' seconds per movie'\n",
      "    return n_movies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load (or save if does not exist) the tokenized data)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is sensible to maybe pursue a POS tagging strategy, and then use only verbs, for example, etc to catogorize some genres.\n",
      "\n",
      "However, it is not needed as a first iteration, and so we will stick with simple tokens (words...) for now, and apply POS tagging later, if needed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_tokenized_movies(n_movies):\n",
      "    with open('movies_tokenized.json','w') as fid:\n",
      "        for movie in n_movies:\n",
      "            json.dump(movie,fid)\n",
      "            fid.write('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_tokenized_movies():\n",
      "    n_movies = []\n",
      "    cnt = 1\n",
      "    L=10000\n",
      "    try:\n",
      "        for line in open('movies_tokenized.json','r'):\n",
      "            if cnt%L == L-1:           \n",
      "                print \"loading line \" + str(cnt)\n",
      "            cnt+=1\n",
      "            n_movies.append(json.loads(line))\n",
      "    except:\n",
      "        return None\n",
      "    return n_movies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_movies = load_tokenized_movies()\n",
      "if not n_movies:\n",
      "    print 'File not found, creating tokens'\n",
      "    n_movies = pos_tag_plots(movies, is_save = True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "File not found, creating tokens\n",
        "no previous file found ./movies_tokenized.json\n",
        "Finished processing 9999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 19999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 29999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 39999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 49999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 59999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 69999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 79999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 89999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 99999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished processing 109999 movies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done with 111934! 0.00308994827321 seconds per movie"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(n_movies)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "111934"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create a count of each token inside each genre"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We count a token that appears multiple times inside one movie once (notice the \"set\" operation for that).\n",
      "\n",
      "genres hold a structure such that we know for each genre, and each token, how many time it appeared.\n",
      "\n",
      "Meanwhile, for each token we also count in how many movies it appeared in total.\n",
      "\n",
      "We also count how many movies are in each genre.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genres = {}\n",
      "tokens_count = defaultdict(int)\n",
      "genres_count = defaultdict(int)\n",
      "N_tokens = 0\n",
      "cnt = 1\n",
      "L = 10000\n",
      "for movie in n_movies:\n",
      "    if cnt%L == L-1:           \n",
      "        print 'Processed ' + str(cnt) + ' movies so far'\n",
      "    cnt+=1\n",
      "    for genre in movie['genres']:\n",
      "        genres_count[genre] += 1\n",
      "    for token in set(movie['tokens']):\n",
      "        N_tokens += 1\n",
      "        tokens_count[token] += 1\n",
      "        for genre in movie['genres']:\n",
      "            if not genres.has_key(genre):\n",
      "                genres[genre]= {}\n",
      "            if not genres[genre].has_key(token):\n",
      "                genres[genre][token] = {'count':1, 'tf_in_genre':None , 'tf_tot':None, 'idf':None}\n",
      "            else:\n",
      "                genres[genre][token]['count'] += 1\n",
      "print 'done'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processed 9999 movies so far\n",
        "Processed 19999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 29999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 39999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 49999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 59999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 69999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 79999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 89999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 99999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processed 109999 movies so far"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Calculate Tf-Idf"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We recreate the classic TF-IDF in the sense that we want to know how much a token is frequent inside a genre, vs. how much it is frequent in the \"general\" populace.\n",
      "\n",
      "You can look at http://en.wikipedia.org/wiki/Tf%E2%80%93idf for a refresher"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We try two \"IDF\"s - one is log2(1/DF), where DF is the frequncy in the general populace.\n",
      "\n",
      "The second which we call \"IDF2\" is simply (1/DF)\n",
      "\n",
      "Note that we dont need to worry avout DF = 0 since we impose a threshold, both absolute (minimum appearance in the genre) and relative (minimum probability of appearance in the genre)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_tf_idf(filename,stats, genre):\n",
      "    with open(filename,'a') as fid:\n",
      "        for genre_word in stats[genre]:\n",
      "            fid.write(genre + ',' + genre_word[0] + ',')\n",
      "            json.dump(genre_word[1],fid)\n",
      "            fid.write('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "WORD_REL_THR = 0.10\n",
      "WORD_ABS_THR = 10\n",
      "\n",
      "\n",
      "delete_file('tf-idf.txt')\n",
      "delete_file('tf-idf2.txt')\n",
      "\n",
      "tf_idf_stats = {}   \n",
      "tf_idf2_stats = {}\n",
      "\n",
      "for genre, count in genres.iteritems():\n",
      "    genre_list = []\n",
      "    for token in genres[genre]:           \n",
      "        genre_word = genres[genre][token]\n",
      "        if genre_word['count'] < WORD_ABS_THR:\n",
      "            continue\n",
      "        # calculate the frequncy of a token inside the genre\n",
      "        genre_word['tf_in_genre'] = round(float(genre_word['count']) / genres_count[genre], 5)\n",
      "        if genre_word['tf_in_genre'] > WORD_REL_THR:\n",
      "            # calculate the frequency of a token in all genres\n",
      "            genre_word['tf_tot'] = round(float(tokens_count[token]) / len(n_movies),3)\n",
      "            genre_word['idf'] = math.log(1.0/genre_word['tf_tot'],2)\n",
      "            genre_word['tf-idf'] = round(genre_word['idf'] * genre_word['tf_in_genre'],3)\n",
      "            genre_word['idf2'] = round(1.0/genre_word['tf_tot'],1)\n",
      "            genre_word['tf-idf2'] = round(genre_word['idf2'] * genre_word['tf_in_genre'],2)\n",
      "\n",
      "            #line = '\\tToken: ' + token + ', count: ' + str(genre_word['count']) +', tf: ' + str(genre_word['tf_in_genre']) + ', tf_tot: ' + str(genre_word['tf_tot']) + ', idf: ' + str(genre_word['idf']) + ', tf-idf: ' + str(genre_word['tf-idf'])\n",
      "            #print line\n",
      "            #fid.writelines( line + '\\n')\n",
      "            genre_list.append([token,genre_word])\n",
      "            \n",
      "    # note that we apply the generatos to make them into lists, because we want to use them several times...\n",
      "    tf_idf_stats[genre] = [x for x in reversed(sorted(genre_list, key=lambda x: x[1]['tf-idf']))]\n",
      "    tf_idf2_stats[genre] = [x for x in reversed(sorted(genre_list, key=lambda x: x[1]['tf-idf2']))]\n",
      "    \n",
      "    save_tf_idf('tf-idf.txt',tf_idf_stats, genre)\n",
      "    save_tf_idf('tf-idf2.txt',tf_idf2_stats, genre)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "old file deleted, ./tf-idf.txt\n",
        "old file deleted, ./tf-idf2.txt\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Finding the features that cover each genre (and hope it's enough)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets try to find, for each genre the list of high tf-idf tokens that spans all of it (or most)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SCORE_THR = 1.3\n",
      "genre_key_words = {}\n",
      "for genre in genres:\n",
      "    print 'Processing genre: ' + genre\n",
      "    genre_movies = [movie for movie in n_movies if genre in movie['genres']]\n",
      "        \n",
      "    for k in range(1,100):\n",
      "        topK = [(x[0],x[1]['tf-idf2']) for x in tf_idf2_stats[genre][:k]]\n",
      "        minimum_score = x[1]['tf-idf2']\n",
      "        if minimum_score < SCORE_THR:\n",
      "            finalK = k - 1\n",
      "            break\n",
      "    \n",
      "        cnt_yes = 0\n",
      "        cnt_no = 0\n",
      "        \n",
      "        for movie in genre_movies:\n",
      "            if genre in movie['genres']:\n",
      "                covered = False\n",
      "                for token in [x[0] for x in topK]:\n",
      "                    if token in movie['tokens']:\n",
      "                        covered = True\n",
      "                if covered:\n",
      "                    cnt_yes +=1\n",
      "                else:\n",
      "                    cnt_no +=1\n",
      "        finalK = k\n",
      "        coverage = cnt_yes / float(cnt_yes+cnt_no)\n",
      "        if coverage > 0.95:\n",
      "            break\n",
      "    genre_key_words[genre] = finalK,cnt_yes, cnt_no, minimum_score, coverage, topK\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing genre: Sci-Fi\n",
        "Processing genre: Crime"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Romance"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Animation"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Music"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Adult"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Comedy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: War"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Horror"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Film-Noir"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Adventure"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: News"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Thriller"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Western"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Mystery"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Short"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Lifestyle"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Drama"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Action"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Documentary"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Musical"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: History"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Family"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Fantasy"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing genre: Sport"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for genre, typical_words in genre_key_words.iteritems():\n",
      "    print genre, typical_words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sci-Fi (32, 4413, 211, 1.34, 0.9543685121107266, [(u'planet', 14.6), (u'alien', 12.47), (u'scientist', 10.84), (u'earth', 10.73), (u'space', 9.17), (u'human', 4.69), (u'futur', 4.67), (u'evil', 4.19), (u'power', 2.94), (u'mysteri', 2.69), (u'save', 2.15), (u'secret', 2.12), (u'discov', 2.12), (u'fight', 2.05), (u'group', 2.05), (u'world', 1.98), (u'must', 1.95), (u'use', 1.87), (u'forc', 1.83), (u'call', 1.76), (u'now', 1.57), (u'name', 1.55), (u'peopl', 1.46), (u'onli', 1.44), (u'can', 1.44), (u'kill', 1.4), (u'been', 1.4), (u'befor', 1.4), (u'into', 1.39), (u'begin', 1.38), (u'where', 1.35), (u'which', 1.34)])\n",
        "Crime (28, 8243, 422, 1.31, 0.9512983266012695, [(u'crimin', 5.79), (u'crime', 5.54), (u'detect', 5.42), (u'polic', 4.79), (u'investig', 3.76), (u'murder', 3.7), (u'gang', 3.4), (u'kill', 2.55), (u'money', 2.22), (u'plan', 1.88), (u'soon', 1.51), (u'get', 1.48), (u'name', 1.45), (u'wife', 1.45), (u'himself', 1.43), (u'him', 1.42), (u'help', 1.42), (u'forc', 1.42), (u'befor', 1.39), (u'out', 1.36), (u'turn', 1.36), (u'now', 1.36), (u'also', 1.36), (u'after', 1.34), (u'up', 1.34), (u'find', 1.32), (u'use', 1.31), (u'tri', 1.31)])\n",
        "Romance (25, 12661, 660, 1.41, 0.9504541701073493, [(u'marri', 2.83), (u'fall', 2.72), (u'love', 2.63), (u'meet', 2.19), (u'she', 1.84), (u'beauti', 1.83), (u'daughter', 1.8), (u'girl', 1.73), (u'her', 1.72), (u'doe', 1.69), (u'woman', 1.66), (u'both', 1.63), (u'know', 1.6), (u'want', 1.59), (u'leav', 1.58), (u'return', 1.55), (u'each', 1.53), (u'father', 1.53), (u'soon', 1.52), (u'name', 1.51), (u'decid', 1.51), (u'get', 1.48), (u'him', 1.45), (u'also', 1.43), (u'young', 1.41)])\n",
        "Animation (4, 2830, 3972, 1.27, 0.4160541017347839, [(u'anim', 7.24), (u'littl', 2.05), (u'off', 1.58), (u'use', 1.49), (u'into', 1.27)])\n",
        "Music (14, 2989, 568, 1.26, 0.8403148720832162, [(u'music', 9.9), (u'song', 9.3), (u'band', 8.99), (u'sing', 8.12), (u'rock', 7.33), (u'singer', 7.16), (u'perform', 5.73), (u'danc', 4.78), (u'featur', 4.14), (u'play', 2.51), (u'includ', 2.28), (u'show', 1.97), (u'film', 1.53), (u'also', 1.36), (u'this', 1.26)])\n",
        "Comedy (1, 8729, 22905, 1.27, 0.27593728267054435, [(u'get', 1.38), (u'so', 1.27)])\n",
        "War (17, 3034, 275, 1.26, 0.9168933212450892, [(u'nazi', 12.9), (u'german', 12.0), (u'soldier', 10.75), (u'war', 8.78), (u'armi', 8.37), (u'battl', 4.06), (u'dure', 3.67), (u'american', 3.46), (u'offic', 3.25), (u'fight', 2.57), (u'against', 2.16), (u'men', 2.13), (u'world', 2.13), (u'forc', 2.11), (u'stori', 1.42), (u'between', 1.38), (u'return', 1.37), (u'first', 1.26)])\n",
        "Horror (17, 5986, 955, 1.29, 0.8624117562310907, [(u'dead', 3.16), (u'mysteri', 2.84), (u'murder', 2.58), (u'kill', 2.29), (u'night', 2.2), (u'group', 2.1), (u'hous', 1.98), (u'death', 1.98), (u'begin', 1.85), (u'soon', 1.85), (u'discov', 1.78), (u'turn', 1.55), (u'must', 1.38), (u'start', 1.36), (u'into', 1.35), (u'them', 1.34), (u'befor', 1.34), (u'find', 1.29)])\n",
        "Film-Noir (25, 404, 11, 1.93, 0.9734939759036144, [(u'suspect', 7.47), (u'murder', 6.23), (u'detect', 5.9), (u'killer', 5.77), (u'polic', 5.46), (u'crime', 5.26), (u'investig', 4.67), (u'prison', 4.37), (u'kill', 3.87), (u'involv', 3.79), (u'money', 2.96), (u'believ', 2.89), (u'plan', 2.78), (u'wife', 2.74), (u'husband', 2.63), (u'night', 2.62), (u'soon', 2.09), (u'marri', 2.07), (u'had', 2.05), (u'fall', 2.04), (u'escap', 2.02), (u'know', 1.96), (u'goe', 1.94), (u'later', 1.94), (u'him', 1.93)])\n",
        "Western (30, 4101, 212, 1.67, 0.9508462786923255, [(u'rancher', 24.81), (u'cattl', 21.94), (u'outlaw', 21.35), (u'ranch', 19.77), (u'sheriff', 16.03), (u'gold', 10.21), (u'hors', 8.93), (u'gang', 8.02), (u'indian', 7.64), (u'ride', 6.55), (u'town', 4.25), (u'owner', 3.92), (u'arriv', 3.75), (u'kill', 3.2), (u'men', 3.08), (u'head', 2.81), (u'murder', 2.67), (u'plan', 2.67), (u'money', 2.54), (u'escap', 2.45), (u'learn', 2.43), (u'brother', 2.26), (u'daughter', 2.18), (u'fight', 2.03), (u'bring', 1.99), (u'return', 1.92), (u'off', 1.86), (u'then', 1.79), (u'been', 1.69), (u'him', 1.67)])\n",
        "News (18, 772, 68, 1.24, 0.919047619047619, [(u'news', 8.96), (u'interview', 5.07), (u'documentari', 3.87), (u'our', 3.68), (u'explor', 3.2), (u'peopl', 2.48), (u'we', 2.44), (u'were', 2.3), (u'show', 2.29), (u'film', 2.09), (u'how', 1.88), (u'most', 1.66), (u'this', 1.49), (u'world', 1.45), (u'look', 1.42), (u'stori', 1.41), (u'follow', 1.37), (u'through', 1.35), (u'over', 1.24)])\n",
        "Thriller (33, 10189, 510, 1.36, 0.9523319936442658, [(u'investig', 3.38), (u'murder', 3.31), (u'polic', 2.83), (u'dead', 2.74), (u'mysteri', 2.61), (u'kill', 2.52), (u'secret', 2.11), (u'death', 2.0), (u'soon', 1.87), (u'seem', 1.81), (u'begin', 1.78), (u'discov', 1.76), (u'must', 1.66), (u'howev', 1.57), (u'call', 1.57), (u'wife', 1.55), (u'know', 1.54), (u'forc', 1.53), (u'befor', 1.52), (u'name', 1.51), (u'find', 1.49), (u'turn', 1.49), (u'now', 1.47), (u'been', 1.46), (u'start', 1.43), (u'help', 1.39), (u'himself', 1.39), (u'what', 1.38), (u'after', 1.38), (u'becom', 1.38), (u'tri', 1.37), (u'onli', 1.36), (u'woman', 1.36)])\n",
        "Adult (18, 533, 27, 1.42, 0.9517857142857142, [(u'erot', 33.96), (u'sex', 17.0), (u'sexual', 15.17), (u'seduc', 13.82), (u'husband', 2.86), (u'women', 2.67), (u'girl', 2.1), (u'beauti', 2.01), (u'then', 1.9), (u'woman', 1.88), (u'anoth', 1.78), (u'her', 1.76), (u'she', 1.74), (u'final', 1.72), (u'some', 1.56), (u'each', 1.51), (u'show', 1.47), (u'-', 1.42)])\n",
        "Mystery (30, 4733, 249, 1.33, 0.9500200722601365, [(u'detect', 6.08), (u'investig', 5.38), (u'murder', 4.67), (u'mysteri', 4.66), (u'polic', 3.14), (u'dead', 2.77), (u'secret', 2.12), (u'death', 2.11), (u'kill', 2.09), (u'seem', 2.08), (u'discov', 1.99), (u'night', 1.8), (u'begin', 1.71), (u'soon', 1.64), (u'lead', 1.64), (u'call', 1.62), (u'find', 1.6), (u'befor', 1.58), (u'been', 1.57), (u'woman', 1.53), (u'had', 1.51), (u'know', 1.5), (u'was', 1.46), (u'name', 1.45), (u'there', 1.43), (u'man', 1.38), (u'help', 1.37), (u'tri', 1.34), (u'wife', 1.34), (u'what', 1.33)])\n",
        "Short (0, 4733, 249, 1.15, 0.9500200722601365, [(u'film', 1.15)])\n",
        "Lifestyle (0, 4733, 249, 1.15, 0.9500200722601365, [])\n",
        "Drama (12, 34148, 10005, 1.28, 0.7734015808665323, [(u'mother', 1.5), (u'son', 1.49), (u'father', 1.45), (u'wife', 1.42), (u'love', 1.4), (u'famili', 1.35), (u'young', 1.35), (u'woman', 1.32), (u'fall', 1.31), (u'she', 1.31), (u'leav', 1.3), (u'life', 1.3), (u'her', 1.28)])\n",
        "Action (33, 10037, 509, 1.37, 0.9517352550730135, [(u'gang', 3.36), (u'kill', 2.71), (u'polic', 2.7), (u'fight', 2.67), (u'against', 2.19), (u'forc', 2.04), (u'escap', 2.01), (u'name', 1.98), (u'murder', 1.98), (u'must', 1.95), (u'brother', 1.91), (u'plan', 1.9), (u'now', 1.8), (u'help', 1.62), (u'son', 1.61), (u'down', 1.57), (u'know', 1.53), (u'befor', 1.53), (u'daughter', 1.51), (u'been', 1.5), (u'also', 1.5), (u'set', 1.48), (u'use', 1.44), (u'himself', 1.43), (u'them', 1.42), (u'after', 1.41), (u'out', 1.41), (u'then', 1.4), (u'onli', 1.39), (u'return', 1.38), (u'find', 1.38), (u'get', 1.37), (u'him', 1.37)])\n",
        "Documentary (21, 14923, 731, 1.33, 0.953302670244027, [(u'documentari', 5.94), (u'interview', 4.75), (u'explor', 3.22), (u'we', 2.59), (u'film', 2.56), (u'journey', 2.38), (u'these', 2.18), (u'most', 2.06), (u'peopl', 1.99), (u'mani', 1.93), (u'how', 1.84), (u'world', 1.73), (u'through', 1.72), (u'follow', 1.7), (u'this', 1.6), (u'stori', 1.58), (u'show', 1.55), (u'year', 1.5), (u'was', 1.44), (u'look', 1.39), (u'first', 1.33)])\n",
        "Musical (30, 2904, 140, 1.33, 0.9540078843626807, [(u'sing', 8.66), (u'danc', 5.85), (u'music', 5.48), (u'marri', 2.75), (u'fall', 2.22), (u'love', 1.98), (u'name', 1.86), (u'show', 1.82), (u'meet', 1.79), (u'daughter', 1.79), (u'doe', 1.73), (u'want', 1.72), (u'girl', 1.7), (u'play', 1.62), (u'decid', 1.6), (u'both', 1.56), (u'leav', 1.54), (u'get', 1.54), (u'son', 1.54), (u'she', 1.51), (u'soon', 1.51), (u'then', 1.49), (u'know', 1.48), (u'come', 1.46), (u'also', 1.46), (u'her', 1.45), (u'return', 1.42), (u'do', 1.38), (u'like', 1.35), (u'him', 1.33)])\n",
        "History (20, 2834, 283, 1.19, 0.9092075713827398, [(u'histori', 6.31), (u'war', 3.61), (u'documentari', 2.73), (u'american', 2.55), (u'were', 2.47), (u'dure', 2.21), (u'stori', 1.98), (u'against', 1.96), (u'film', 1.76), (u'peopl', 1.68), (u'was', 1.66), (u'through', 1.5), (u'world', 1.48), (u'most', 1.46), (u'tell', 1.45), (u'how', 1.45), (u'year', 1.39), (u'this', 1.38), (u'first', 1.36), (u'between', 1.33), (u'which', 1.19)])\n",
        "Family (11, 5835, 2048, 1.29, 0.7402004313078777, [(u'boy', 2.0), (u'littl', 1.96), (u'name', 1.53), (u'famili', 1.45), (u'like', 1.42), (u'home', 1.42), (u'show', 1.38), (u'then', 1.38), (u'get', 1.37), (u'help', 1.36), (u'so', 1.34), (u'use', 1.29)])\n",
        "Adventure (27, 6521, 533, 1.29, 0.9244400340232493, [(u'adventur', 4.9), (u'save', 2.33), (u'escap', 2.16), (u'fight', 2.08), (u'must', 1.8), (u'against', 1.78), (u'name', 1.71), (u'forc', 1.64), (u'kill', 1.63), (u'help', 1.63), (u'set', 1.6), (u'discov', 1.58), (u'off', 1.51), (u'them', 1.44), (u'now', 1.42), (u'world', 1.42), (u'return', 1.4), (u'use', 1.4), (u'befor', 1.39), (u'where', 1.37), (u'find', 1.36), (u'way', 1.36), (u'also', 1.36), (u'they', 1.34), (u'back', 1.32), (u'been', 1.31), (u'father', 1.3), (u'by', 1.29)])\n",
        "Fantasy (18, 4376, 635, 1.29, 0.8732787866693275, [(u'magic', 8.15), (u'evil', 5.12), (u'power', 2.67), (u'mysteri', 2.51), (u'must', 1.8), (u'world', 1.71), (u'name', 1.64), (u'discov', 1.53), (u'help', 1.44), (u'can', 1.44), (u'into', 1.4), (u'girl', 1.39), (u'where', 1.39), (u'which', 1.34), (u'back', 1.34), (u'now', 1.34), (u'himself', 1.32), (u'find', 1.31), (u'old', 1.29)])\n",
        "Sport (16, 1535, 265, 1.26, 0.8527777777777777, [(u'sport', 21.25), (u'coach', 20.92), (u'footbal', 19.72), (u'player', 13.58), (u'team', 9.18), (u'game', 7.0), (u'race', 5.64), (u'win', 5.19), (u'play', 2.63), (u'fight', 2.11), (u'against', 1.82), (u'world', 1.73), (u'most', 1.62), (u'show', 1.6), (u'follow', 1.58), (u'first', 1.45), (u'some', 1.26)])\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Create a bag of words for stemmed 1-grams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bow = set()\n",
      "stemmer = nltk.stem.snowball.EnglishStemmer()\n",
      "for genre_stats in genre_key_words.values():\n",
      "    bow.update([y[0] for y in genre_stats[5]]),\n",
      "\n",
      "with open('bag-of-words.pickle','w') as f:\n",
      "    pickle.dump(bow,f)\n",
      "with open('genre-key-words.pickle','w') as f:\n",
      "    pickle.dump(genre_key_words,f)\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Midway reflection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that some categories are well covered, such as Crime or Romance, and some are not as good. \n",
      "\n",
      "The problematic ones are Animation and Comedy\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'The size of the Animation category is: ' + str(genres_count['Animation'])\n",
      "print 'The size of the Comedy category is: ' + str(genres_count['Comedy'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The size of the Animation category is: 6841\n",
        "The size of the Comedy category is: 31758\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, animation just does not have that many movies, but comedy certainly does."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[(x[0],x[1]['tf-idf2']) for x in tf_idf2_stats['Animation'][:4]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[(u'anim', 7.24), (u'littl', 2.05), (u'off', 1.58), (u'use', 1.49)]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[(x[0],x[1]['tf-idf2']) for x in tf_idf2_stats['Comedy'][:4]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[(u'get', 1.38), (u'so', 1.27), (u'just', 1.25), (u'decid', 1.25)]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It seems these categories just have a very unified scattering of words, so it will be very hard to categorize them based on a simple 1-Gram, we should not even try.\n",
      "\n",
      "Maybe we should use 2-Grams or using the titles of the movies. We will get back to this later on.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Calculate the features of a new movie"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create the bag-of-words"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A feature for FilmNoir and Western (year of release)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = [(movie['genres'], int(movie['year'])) for movie in movies if not 'Film-Noir' in movie['genres']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = [int(movie['year']) for movie in movies if 'Film-Noir' in movie['genres']]\n",
      "print max(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1959\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, no film noir came out after 1959...\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "hist([int(z[1]) for z in x])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "(array([  592,  2356,  2243,  6229,  7084,  6910,  8203, 10389, 21427, 46086]),\n",
        " array([ 1888. ,  1900.8,  1913.6,  1926.4,  1939.2,  1952. ,  1964.8,\n",
        "        1977.6,  1990.4,  2003.2,  2016. ]),\n",
        " <a list of 10 Patch objects>)"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Look at western year histogram"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = [int(movie['year']) for movie in movies if 'Western' in movie['genres']]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4313\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "hist(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "(array([  30,  283,  517, 1230, 1086,  368,  313,   77,  102,  307]),\n",
        " array([ 1899. ,  1910.5,  1922. ,  1933.5,  1945. ,  1956.5,  1968. ,\n",
        "        1979.5,  1991. ,  2002.5,  2014. ]),\n",
        " <a list of 10 Patch objects>)"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "DecsionTree Classifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "We will choose a decision tree, since it is easy to debug, and easy to interpret.\n",
      "\n",
      "Also, it allows us to create a boolean classifier for each class and follow the tree down to understand the probability of success"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define the features"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We wil try to define some extra features that can help differentiate specific classes (such as year of the movie, etc)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The way we get to the following ngrams is we look at each genre top tf-idf terms.\n",
      "\n",
      "Then we look (using cat, grep etc in command line) for common phrases there. \n",
      "\n",
      "It would be wize to do this automatically of course, but for now this is faster...\n",
      "\n",
      "For example for sci-fi the word \"world\" seems to be important we can use the following to explore this in shell:\n",
      ">>cat movies_train.json |grep Sci-Fi  | grep force "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngrams_qualifiers = {}\n",
      "ngrams_qualifiers['Sci-Fi'] = ['over the world','save the world','another world','extinct world','a world of', 'worlds','real world','of the world','force of','evil forces','into space','into the future','from the past']\n",
      "ngrams_qualifiers['Romance'] = ['fall in love']\n",
      "ngrams_qualifiers_set = set()\n",
      "for genre, ql in ngrams_qualifiers.iteritems():\n",
      "    ngrams_qualifiers_set.update(ql)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Important note:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This method can greatly enhance the performance. It focuses on terms that highly cover a genre (i.e. have a high chance of appearing in it) and fine-tunes the variations of the phrases it appears in.\n",
      "However, this would take several more hours of manual work, and it seems to me a better use of the time would be to productionize first.\n",
      "\n",
      "So, this is a possible enhancement, demonstrated for Sci-Fi here only.\n",
      "\n",
      "Just to give you a sense. the sci-fi thing itslef improves the \"misdetect\" accuracy by 3% (from 67% to 64%)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Important Note"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_feature_vec(movie = None):\n",
      "    \n",
      "    feature_vector = []\n",
      "    if movie == None:       \n",
      "        for ngram in ngrams_qualifiers_set:\n",
      "            feature_vector.append('has(%s)' %ngram)\n",
      "        for word in bow:      \n",
      "            feature_vector.append('has(%s)' %word)\n",
      "        feature_vector.append('before(1960)')\n",
      "        feature_vector.append('after(2002)')\n",
      "        feature_vector.append('between(1922-1970)')  \n",
      "    else:\n",
      "        stemmer = nltk.stem.snowball.EnglishStemmer()\n",
      "        tokens = [stemmer.stem(token) for token in nltk.word_tokenize(movie['plot'].lower())]\n",
      "        ret_dict = {}\n",
      "        for ngram in ngrams_qualifiers_set:\n",
      "            feature_vector.append(ngram in movie['plot'])\n",
      "        for word in bow:      \n",
      "            feature_vector.append(word in tokens)\n",
      "        feature_vector.append(int(movie['year'])<1960)\n",
      "        feature_vector.append(int(movie['year'])>2002)\n",
      "        feature_vector.append(int(movie['year'])<1971 and int(movie['year'])>1921)\n",
      "    return feature_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Split into the train and test-dev sets and calculate feature vectors for training set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We split the training data into about 90% we use for actual training, and \"test-dev\" which is 10%, used to test our classifier internally, and fine tune.\n",
      "\n",
      "This is useful so we do not over-fit the classifier to the actual test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_set = []\n",
      "N_train = 100000\n",
      "train_input = movies[:N_train]\n",
      "test_dev = movies[N_train:]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found features for 9999 movies in training set out of 100000\n",
        "Found features for 19999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 29999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 39999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 49999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 59999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 69999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 79999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 89999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 99999 movies in training set out of 100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CREATE_NEW_FEATURES_SET = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if CREATE_NEW_FEATURES_SET:\n",
      "    cnt = 0\n",
      "    L=10000\n",
      "    for movie in train_input:\n",
      "        if cnt%L == L-1:           \n",
      "            print \"Found features for \" + str(cnt) + \" movies in training set out of \" + str(N_train)\n",
      "        cnt +=1\n",
      "        train_set.append(get_feature_vec(movie))    \n",
      "    with open('training_set_features.pickle','w') as f:\n",
      "        pickle.dump(train_set,f)\n",
      "else:\n",
      "    with open('training_set_features.pickle','r') as f:\n",
      "    train_set = pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "train the classifiers"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import StringIO, pydot \n",
      "from sklearn import tree"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Choose the parameters of the decision tree"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need to define a max-depth, since we have many (some 300) features. We will choose a depth of 10.\n",
      "\n",
      "We also set the minimum per leaf to 5, so we do not overfit.\n",
      "\n",
      "We also set \"compute importance\" to True, so we can analyze the features later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_classifier(clf, genre):\n",
      "    dot_data = StringIO.StringIO() \n",
      "    tree.export_graphviz(clf, out_file=dot_data) \n",
      "    graph = pydot.graph_from_dot_data(dot_data.getvalue()) \n",
      "    graph.write_pdf('viz/' + genre + 'classifier.pdf') \n",
      "\n",
      "def train_genre_classifier(genre, train_input, train_set):\n",
      "    \n",
      "    labels = [genre in x['genres'] for x in train_input]\n",
      "    clf = tree.DecisionTreeClassifier(min_samples_leaf = 5, max_depth = 10, compute_importances = True)\n",
      "    clf = clf.fit(train_set, labels)\n",
      "    #print 'Dumping to pdf'\n",
      "    #plot_classifier(clf, genre)\n",
      "    return clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_classifiers = {}\n",
      "for genre in genres:\n",
      "    tic = time()\n",
      "    genre_classifiers[genre] = train_genre_classifier(genre, train_input, train_set)\n",
      "    toc = time()\n",
      "    print 'Trained genre: ' + genre + ', took ' + str(int(toc-tic)) + ' seconds'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trained genre: Sci-Fi, took 15 seconds\n",
        "Trained genre: Crime, took 7 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Romance, took 13 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Animation, took 9 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Music, took 6 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Adult, took 8 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Comedy, took 12 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: War, took 6 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Horror, took 8 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Film-Noir, took 5 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Adventure, took 9 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: News, took 11 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Thriller, took 9 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Western, took 6 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Mystery, took 7 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Short, took 14 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Lifestyle, took 3 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Drama, took 13 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Action, took 8 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Documentary, took 13 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Musical, took 9 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: History, took 10 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Family, took 12 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Fantasy, took 10 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trained genre: Sport, took 7 seconds"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('classifiers.pickle','w') as f:\n",
      "    pickle.dump(genre_classifiers,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prepare test-dev set features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calc_features(movies_set):\n",
      "    set_features = []\n",
      "    cnt = 0\n",
      "    L=1000\n",
      "    for movie in movies_set:\n",
      "        if (cnt-1)%L == L-1:           \n",
      "            print \"Found features for \" + str(cnt) + \" movies in set out of \" + str(len(movies_set))\n",
      "        cnt +=1\n",
      "        set_features.append(get_feature_vec(movie))\n",
      "    return set_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_dev_features = calc_features(movies_set = test_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found features for 0 movies in set out of 11934\n",
        "Found features for 1000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 2000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 3000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 4000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 5000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 6000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 7000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 8000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 9000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 10000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 11000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify_genres(genres, set_features, movies_set, genre_classifiers, is_verbose = False):   \n",
      "    print 'Starting classification'\n",
      "    genre_probabilities = {}\n",
      "    for genre in genres:\n",
      "        X = set_features\n",
      "        labels = [genre in x['genres'] for x in movies_set]\n",
      "        if is_verbose:\n",
      "            print genre + \" score: \" + str(round(genre_classifiers[genre].score(X,labels),2))\n",
      "        \n",
      "        # lets create a probability vector\n",
      "        genre_probabilities[genre] = [classification_result[1] for classification_result in genre_classifiers[genre].predict_proba(set_features)]\n",
      "    print 'Finished classification'\n",
      "    return genre_probabilities\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "The following score is the one supplied by the classifier framework. Not exactly what we need though, but let's look at it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genre_probabilities = classify_genres(genres,test_dev_features, test_dev, genre_classifiers, True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting classification\n",
        "Sci-Fi score: 0.97"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Crime score: 0.93"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Romance score: 0.87"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Animation score: 0.95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Music score: 0.97"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Adult score: 0.99"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Comedy score: 0.73"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "War score: 0.96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Horror score: 0.93"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Film-Noir score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Adventure score: 0.93"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "News score: 0.99"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Thriller score: 0.91"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Western score: 0.97"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Mystery score: 0.95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Short score: 0.72"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Lifestyle score: 1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Drama score: 0.65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Action score: 0.9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Documentary score: 0.9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Musical score: 0.97"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "History score: 0.97"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Family score: 0.94"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Fantasy score: 0.96"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sport score: 0.99"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished classification"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Note that the score might be misleading. It relates to P(classification == labeling) and not Precision or Recall, which are much lower in reality."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Calculate genres vectors and metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def render_genres(genres, genre_probabilities, movies_set):\n",
      "    \n",
      "    genres_vector = genres.keys()\n",
      "    print genres_vector\n",
      "    for i in xrange(len(movies_set)):\n",
      "        if (i-1)%L == L-1:           \n",
      "            print \"Rendered genres vec for \" + str(i) + \" movies in test-dev set\"\n",
      "        movie = movies_set[i]\n",
      "        classified_genres_vector = []\n",
      "        original_genres_vector = []\n",
      "        for genre in genres_vector:\n",
      "            classified_genres_vector.append(genre_probabilities[genre][i])\n",
      "            original_genres_vector.append(1.0 if genre in movie['genres'] else 0.0)\n",
      "            movie['original_genres_vector'] = original_genres_vector\n",
      "            movie['classified_genres_vector'] = classified_genres_vector\n",
      "        err_vec = np.array((movie['original_genres_vector']) - np.array(movie['classified_genres_vector']))\n",
      "        movie['metric-misdetect'] = mean([1.0 - classified_genres_vector[j] for j in xrange(len(err_vec)) if original_genres_vector[j] == 1.0])\n",
      "        movie['metric-precision'] = mean([abs(x) for x in err_vec])\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "render_genres(genres, genre_probabilities, movies_set = test_dev)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'Sci-Fi', u'Crime', u'Romance', u'Animation', u'Music', u'Adult', u'Comedy', u'War', u'Horror', u'Film-Noir', u'Adventure', u'News', u'Thriller', u'Western', u'Mystery', u'Short', u'Lifestyle', u'Drama', u'Action', u'Documentary', u'Musical', u'History', u'Family', u'Fantasy', u'Sport']\n",
        "Rendered genres vec for 0 movies in test-dev set\n",
        "Rendered genres vec for 10000 movies in test-dev set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Average \"misdetect\" is ' + str(mean([movie['metric-misdetect'] for movie in test_dev]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Average \"misdetect\" is 0.645628935113\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_classification(movie, genres_vector):\n",
      "    st = 'Movie: ' + movie['name'] + ' #### Originally classified as:\\t\\t ' + \",\".join([genres_vector[i]  for i in xrange(len(genres_vector)) if movie['original_genres_vector'][i] == 1.0])\n",
      "    st = st + '\\nWe classified as: \\t\\t\\t\\t\\t' + \",\".join([str((str(genres_vector[i]), str(int(movie['classified_genres_vector'][i] *100)) + '%'))  for i in xrange(len(genres_vector)) if movie['classified_genres_vector'][i] > 0.1])\n",
      "    return st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for movie in test_dev[0:20]:\n",
      "    print print_classification(movie, genres.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Movie: The Traveler #### Originally classified as: Short,Documentary\n",
        "We classified as: \t\t\t\t\t('Comedy', '16%'),('Short', '36%'),('Drama', '29%'),('Documentary', '53%')\n",
        "Movie: The Travelers #### Originally classified as: Drama\n",
        "We classified as: \t\t\t\t\t('Romance', '19%'),('Comedy', '14%'),('Horror', '10%'),('Short', '46%'),('Drama', '54%'),('Documentary', '10%')\n",
        "Movie: The Traveling Salesman #### Originally classified as: Comedy,Drama\n",
        "We classified as: \t\t\t\t\t('Comedy', '38%'),('Short', '87%'),('Drama', '28%')\n",
        "Movie: The Traveling Saleswoman #### Originally classified as: Comedy,Western\n",
        "We classified as: \t\t\t\t\t('Romance', '19%'),('Comedy', '63%'),('Adventure', '11%'),('Drama', '28%')\n",
        "Movie: The Travelling Artist #### Originally classified as: Horror,Short,Fantasy\n",
        "We classified as: \t\t\t\t\t('Comedy', '27%'),('Short', '56%'),('Drama', '60%')\n",
        "Movie: The Travelogues #### Originally classified as: Crime,Romance,Comedy,War,Horror,Thriller,Western,Short,Drama,Action,Documentary,Family,Fantasy\n",
        "We classified as: \t\t\t\t\t('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: The Travis McFarland Club #### Originally classified as: Romance,Comedy,Short\n",
        "We classified as: \t\t\t\t\t('Romance', '24%'),('Comedy', '27%'),('Adventure', '13%'),('Short', '56%'),('Drama', '54%')\n",
        "Movie: The Treasure Box #### Originally classified as: Adult,Comedy,Mystery\n",
        "We classified as: \t\t\t\t\t('Romance', '13%'),('Adult', '15%'),('Comedy', '34%'),('Horror', '10%'),('Thriller', '15%'),('Mystery', '11%'),('Short', '20%'),('Drama', '54%')\n",
        "Movie: The Treasure of Lost Canyon #### Originally classified as: Adventure,Western\n",
        "We classified as: \t\t\t\t\t('Romance', '16%'),('Comedy', '40%'),('Short', '47%'),('Drama', '44%')\n",
        "Movie: The Treasure of Pancho Villa #### Originally classified as: Romance,Western\n",
        "We classified as: \t\t\t\t\t('Animation', '14%'),('Short', '47%'),('Drama', '17%'),('Family', '13%')\n",
        "Movie: The Treasure of the Bandit King #### Originally classified as: Short,Action\n",
        "We classified as: \t\t\t\t\t('Romance', '13%'),('Comedy', '27%'),('Short', '56%'),('Drama', '43%')\n",
        "Movie: The Treasure of the Grotoceans #### Originally classified as: Animation,Short\n",
        "We classified as: \t\t\t\t\t('Animation', '54%'),('Comedy', '31%'),('Family', '17%')\n",
        "Movie: The Treasure of the Sierra Madre #### Originally classified as: Adventure,Western,Drama,Action\n",
        "We classified as: \t\t\t\t\t('Animation', '54%'),('Comedy', '63%'),('Adventure', '16%'),('Western', '64%'),('Short', '47%'),('Drama', '17%'),('Family', '60%')\n",
        "Movie: The Treasure Seekers #### Originally classified as: Adventure,Action\n",
        "We classified as: \t\t\t\t\t('Comedy', '31%'),('Short', '16%'),('Drama', '29%')\n",
        "Movie: The Treasurer's Report #### Originally classified as: Comedy,Short\n",
        "We classified as: \t\t\t\t\t('Animation', '14%'),('Comedy', '40%'),('Short', '47%'),('Drama', '17%'),('Family', '13%')\n",
        "Movie: The Treaty #### Originally classified as: Short\n",
        "We classified as: \t\t\t\t\t('Animation', '12%'),('Comedy', '31%'),('Horror', '24%'),('Short', '16%'),('Drama', '29%'),('Action', '15%')\n",
        "Movie: The Tree #### Originally classified as: Mystery,Short,Drama\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '40%'),('Comedy', '31%'),('Short', '16%'),('Drama', '29%'),('Documentary', '38%')\n",
        "Movie: The Tree #### Originally classified as: Short\n",
        "We classified as: \t\t\t\t\t('Comedy', '42%'),('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: The Tree in a Test Tube #### Originally classified as: Short,Documentary\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '48%'),('Animation', '27%'),('Comedy', '18%'),('Horror', '15%'),('Short', '47%'),('Drama', '17%'),('Documentary', '30%')\n",
        "Movie: The Tree Man #### Originally classified as: Short,Drama,Fantasy\n",
        "We classified as: \t\t\t\t\t('Comedy', '14%'),('Adventure', '16%'),('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "All-together now. Now that we have the whole flow, we'll encapsulate it."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "lets bind it into one function:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def go_classify(movies_set, genres, genre_classifiers, how_much_to_print = 0):\n",
      "    movies_set_features = calc_features(movies_set = movies_set)\n",
      "    genre_probabilities = classify_genres(genres,movies_set_features, movies_set, genre_classifiers, False)\n",
      "    render_genres(genres, genre_probabilities, movies_set = movies_set)\n",
      "    \n",
      "    for movie in movies_set[0:how_much_to_print]:\n",
      "        print print_classification(movie, genres.keys())\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_classify(test_dev, genres, genre_classifiers,20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found features for 0 movies in set out of 11934\n",
        "Found features for 1000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 2000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 3000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 4000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 5000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 6000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 7000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 8000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 9000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 10000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Found features for 11000 movies in set out of 11934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting classification"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished classification"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'Sci-Fi', u'Crime', u'Romance', u'Animation', u'Music', u'Adult', u'Comedy', u'War', u'Horror', u'Film-Noir', u'Adventure', u'News', u'Thriller', u'Western', u'Mystery', u'Short', u'Lifestyle', u'Drama', u'Action', u'Documentary', u'Musical', u'History', u'Family', u'Fantasy', u'Sport']\n",
        "Rendered genres vec for 0 movies in test-dev set\n",
        "Rendered genres vec for 10000 movies in test-dev set"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Movie: The Traveler #### Originally classified as: Short,Documentary\n",
        "We classified as: \t\t\t\t\t('Comedy', '16%'),('Short', '36%'),('Drama', '29%'),('Documentary', '53%')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Movie: The Travelers #### Originally classified as: Drama\n",
        "We classified as: \t\t\t\t\t('Romance', '19%'),('Comedy', '14%'),('Horror', '10%'),('Short', '46%'),('Drama', '54%'),('Documentary', '10%')\n",
        "Movie: The Traveling Salesman #### Originally classified as: Comedy,Drama\n",
        "We classified as: \t\t\t\t\t('Comedy', '38%'),('Short', '87%'),('Drama', '28%')\n",
        "Movie: The Traveling Saleswoman #### Originally classified as: Comedy,Western\n",
        "We classified as: \t\t\t\t\t('Romance', '19%'),('Comedy', '63%'),('Adventure', '11%'),('Drama', '28%')\n",
        "Movie: The Travelling Artist #### Originally classified as: Horror,Short,Fantasy\n",
        "We classified as: \t\t\t\t\t('Comedy', '27%'),('Short', '56%'),('Drama', '60%')\n",
        "Movie: The Travelogues #### Originally classified as: Crime,Romance,Comedy,War,Horror,Thriller,Western,Short,Drama,Action,Documentary,Family,Fantasy\n",
        "We classified as: \t\t\t\t\t('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: The Travis McFarland Club #### Originally classified as: Romance,Comedy,Short\n",
        "We classified as: \t\t\t\t\t('Romance', '24%'),('Comedy', '27%'),('Adventure', '13%'),('Short', '56%'),('Drama', '54%')\n",
        "Movie: The Treasure Box #### Originally classified as: Adult,Comedy,Mystery\n",
        "We classified as: \t\t\t\t\t('Romance', '13%'),('Adult', '15%'),('Comedy', '34%'),('Horror', '10%'),('Thriller', '15%'),('Mystery', '11%'),('Short', '20%'),('Drama', '54%')\n",
        "Movie: The Treasure of Lost Canyon #### Originally classified as: Adventure,Western\n",
        "We classified as: \t\t\t\t\t('Romance', '16%'),('Comedy', '40%'),('Short', '47%'),('Drama', '44%')\n",
        "Movie: The Treasure of Pancho Villa #### Originally classified as: Romance,Western\n",
        "We classified as: \t\t\t\t\t('Animation', '14%'),('Short', '47%'),('Drama', '17%'),('Family', '13%')\n",
        "Movie: The Treasure of the Bandit King #### Originally classified as: Short,Action\n",
        "We classified as: \t\t\t\t\t('Romance', '13%'),('Comedy', '27%'),('Short', '56%'),('Drama', '43%')\n",
        "Movie: The Treasure of the Grotoceans #### Originally classified as: Animation,Short\n",
        "We classified as: \t\t\t\t\t('Animation', '54%'),('Comedy', '31%'),('Family', '17%')\n",
        "Movie: The Treasure of the Sierra Madre #### Originally classified as: Adventure,Western,Drama,Action\n",
        "We classified as: \t\t\t\t\t('Animation', '54%'),('Comedy', '63%'),('Adventure', '16%'),('Western', '64%'),('Short', '47%'),('Drama', '17%'),('Family', '60%')\n",
        "Movie: The Treasure Seekers #### Originally classified as: Adventure,Action\n",
        "We classified as: \t\t\t\t\t('Comedy', '31%'),('Short', '16%'),('Drama', '29%')\n",
        "Movie: The Treasurer's Report #### Originally classified as: Comedy,Short\n",
        "We classified as: \t\t\t\t\t('Animation', '14%'),('Comedy', '40%'),('Short', '47%'),('Drama', '17%'),('Family', '13%')\n",
        "Movie: The Treaty #### Originally classified as: Short\n",
        "We classified as: \t\t\t\t\t('Animation', '12%'),('Comedy', '31%'),('Horror', '24%'),('Short', '16%'),('Drama', '29%'),('Action', '15%')\n",
        "Movie: The Tree #### Originally classified as: Mystery,Short,Drama\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '40%'),('Comedy', '31%'),('Short', '16%'),('Drama', '29%'),('Documentary', '38%')\n",
        "Movie: The Tree #### Originally classified as: Short\n",
        "We classified as: \t\t\t\t\t('Comedy', '42%'),('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: The Tree in a Test Tube #### Originally classified as: Short,Documentary\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '48%'),('Animation', '27%'),('Comedy', '18%'),('Horror', '15%'),('Short', '47%'),('Drama', '17%'),('Documentary', '30%')\n",
        "Movie: The Tree Man #### Originally classified as: Short,Drama,Fantasy\n",
        "We classified as: \t\t\t\t\t('Comedy', '14%'),('Adventure', '16%'),('Short', '56%'),('Drama', '29%'),('Documentary', '16%')\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "all that remains now is to save the genres vector. Together with classifiers.pickle and bag-of-words we have everything needed to classify new "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('genres-list.pickle','w') as f:\n",
      "    pickle.dump(genres.keys(),f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Lets try classifying some new movies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_set = load_training_set('movies_test.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(test_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "1126"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "get the features for each movie"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go_classify(test_set, genres, genre_classifiers,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found features for 0 movies in set out of 1126\n",
        "Found features for 1000 movies in set out of 1126"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting classification"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished classification"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[u'Sci-Fi', u'Crime', u'Romance', u'Animation', u'Music', u'Adult', u'Comedy', u'War', u'Horror', u'Film-Noir', u'Adventure', u'News', u'Thriller', u'Western', u'Mystery', u'Short', u'Lifestyle', u'Drama', u'Action', u'Documentary', u'Musical', u'History', u'Family', u'Fantasy', u'Sport']\n",
        "Rendered genres vec for 0 movies in test-dev set\n",
        "Movie: Akvariumas #### Originally classified as:\t\t Drama\n",
        "We classified as: \t\t\t\t\t('Comedy', '31%'),('Short', '16%'),('Drama', '29%')"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Movie: American Dream #### Originally classified as:\t\t Drama\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '40%'),('Romance', '13%'),('Comedy', '31%'),('Short', '16%'),('Drama', '44%')\n",
        "Movie: Ancient Megastructures #### Originally classified as:\t\t Action,Documentary,History\n",
        "We classified as: \t\t\t\t\t('Short', '41%'),('Drama', '29%'),('Documentary', '76%'),('History', '55%')\n",
        "Movie: Australia's Brainiest Kid #### Originally classified as:\t\t Family\n",
        "We classified as: \t\t\t\t\t('Comedy', '36%'),('Short', '49%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: Banjica #### Originally classified as:\t\t Drama\n",
        "We classified as: \t\t\t\t\t('Comedy', '18%'),('War', '88%'),('Short', '11%'),('Drama', '44%')\n",
        "Movie: Beat the Clock #### Originally classified as:\t\t Family\n",
        "We classified as: \t\t\t\t\t('Animation', '27%'),('Comedy', '40%'),('Short', '47%'),('Drama', '17%'),('Family', '28%')\n",
        "Movie: Best Ranger #### Originally classified as:\t\t Action\n",
        "We classified as: \t\t\t\t\t('Comedy', '16%'),('War', '21%'),('Adventure', '10%'),('Drama', '29%'),('Documentary', '16%')\n",
        "Movie: Chojin sentai Jettoman #### Originally classified as:\t\t Romance,Animation,Drama,Action\n",
        "We classified as: \t\t\t\t\t('Sci-Fi', '100%'),('Romance', '22%'),('Comedy', '27%'),('Horror', '34%'),('Thriller', '26%'),('Drama', '92%'),('Action', '82%'),('Fantasy', '27%')\n",
        "Movie: Consider Your Verdict #### Originally classified as:\t\t Drama\n",
        "We classified as: \t\t\t\t\t('Crime', '25%'),('Animation', '14%'),('Comedy', '40%'),('Thriller', '19%'),('Short', '16%'),('Drama', '29%'),('Family', '13%')\n",
        "Movie: De tijdscapsule #### Originally classified as:\t\t Sci-Fi\n",
        "We classified as: \t\t\t\t\t('Animation', '14%'),('Comedy', '40%'),('Drama', '29%'),('Family', '13%')\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We see that the results make sense, but there is a lot of room for improvement yet.\n",
      "We need to delve deeper. Maybe alot of the extra taggings (we show alot more possible categories) are because human categorization tends to be more quantized. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could argue that the human classification is wrong, or we could try immitating it. It all depends on what the use is. \n",
      "\n",
      "If the use is for categories in an online site, we should go with human intuition.\n",
      "If the use is for internal purpose of further understanding of the movie (what it is about, what is it's world of context made of, etc), then we should be more hesitant to dismiss our immediate results.\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "The end (hope you like it)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}